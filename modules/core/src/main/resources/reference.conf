# Copyright (c) 2014-present Snowplow Analytics Ltd. All rights reserved.
#
# This software is made available by Snowplow Analytics, Ltd.,
# under the terms of the Snowplow Limited Use License Agreement, Version 1.0
# located at https://docs.snowplow.io/limited-use-license-1.0
# BY INSTALLING, DOWNLOADING, ACCESSING, USING OR DISTRIBUTING ANY PORTION
# OF THE SOFTWARE, YOU AGREE TO THE TERMS OF SUCH LICENSE AGREEMENT.

{

  "license" {
    "accept": "false"
    "accept": ${?ACCEPT_LIMITED_USE_LICENSE}
  }

  "gcpUserAgent": {
    "productName": "Snowplow OSS"
    "productName": ${?GCP_USER_AGENT_PRODUCT_NAME}
    "productVersion": "lake-loader"
  }

  "output": {
    "good": {
      "type": "Delta"
      "type": ${?packaging.output.good.type}
      "dataSkippingColumns": [
        "load_tstamp"
        "collector_tstamp"
        "derived_tstamp"
        "dvce_created_tstamp"
      ]

      "hudiTableOptions": {
        "hoodie.table.name": "events"
        "hoodie.table.keygenerator.class": "org.apache.hudi.keygen.TimestampBasedKeyGenerator"
        "hoodie.table.partition.fields": "load_tstamp"
        "hoodie.keygen.timebased.timestamp.scalar.time.unit": "microseconds"
        "hoodie.keygen.timebased.output.dateformat": "yyyy-MM-dd"
      }

      "hudiWriteOptions": {
        "hoodie.keygen.timebased.timestamp.type": "SCALAR"
        "hoodie.datasource.write.operation": "INSERT"
        "hoodie.datasource.write.reconcile.schema": "true"
        "hoodie.datasource.write.partitionpath.field": "load_tstamp"
        "hoodie.schema.on.read.enable": "true"
        "hoodie.metadata.index.column.stats.column.list": "load_tstamp,collector_tstamp,derived_tstamp,dvce_created_tstamp"
        "hoodie.embed.timeline.server": "false"
        "hoodie.filesystem.view.incr.timeline.sync.enable": "true"
        "hoodie.filesystem.view.type": "SPILLABLE_DISK"
      }

      "catalog": {
        "type": "Hadoop"
        "options": {}
      }
    }
  }

  "inMemBatchBytes": 25600000
  "cpuParallelismFraction": 0.75
  "windowing": "5 minutes"
  "spark": {
    "taskRetries": 3
    "conf": {
      "spark.ui.enabled": "false"
      "spark.local.dir": "/tmp" # This is the default but it's important for us
      "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
      "spark.memory.fraction": "0.3" # Decreased from the Spark default to prevent OOMs
      "spark.sql.parquet.outputTimestampType": "TIMESTAMP_MICROS"
      "spark.sql.parquet.datetimeRebaseModeInWrite": "CORRECTED"
      "spark.memory.storageFraction": "0"
    }
    "gcpUserAgent": ${gcpUserAgent}
  }

  "skipSchemas": []

  "monitoring": {
    "metrics": {
      "statsd": ${snowplow.defaults.statsd}
      "statsd": {
        "prefix": "snowplow.lakeloader"
      }
    }
    "sentry": {
      "tags": {
      }
    }
    "healthProbe": {
      "port": 8000
      "unhealthyLatency": "1 minute"
    }
  }

  "telemetry": ${snowplow.defaults.telemetry}
}
