{
  "output": {
    "good": {
      "type": "Delta"
      "dataSkippingColumns": [
        "load_tstamp"
        "collector_tstamp"
        "derived_tstamp"
        "dvce_created_tstamp"
      ]
    }
  }

  "inMemBatchBytes": 25600000
  "cpuParallelismFraction": 0.75
  "windowing": "5 minutes"
  "spark": {
    "taskRetries": 3
    "conf": {
      "spark.ui.enabled": "false"
      "spark.local.dir": "/tmp" # This is the default but it's important for us
      "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
      "spark.memory.fraction": "0.2" # Decreased from the Spark default to prevent OOMs
      "spark.sql.parquet.outputTimestampType": "TIMESTAMP_MICROS"
      "spark.sql.parquet.datetimeRebaseModeInWrite": "CORRECTED"
    }
  }

  "monitoring": {
    "metrics": {
      "statsd": {
        "port": 8125,
        "tags": {}
        "period": "1 minute"
        "prefix": "snowplow.lakeloader"
      }
    }
    "sentry": {
      "tags": {
      }
    }
    "healthProbe": {
      "port": 8000
      "unhealthyLatency": "15 minutes"
    }
  }

  "telemetry": {
    "disable": false
    "interval": "15 minutes"
    "collectorUri": "collector-g.snowplowanalytics.com"
    "collectorPort": 443
    "secure": true
  }
}
